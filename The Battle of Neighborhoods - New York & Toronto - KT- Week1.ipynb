{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Battle of Neighborhoods - New York & Toronto\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "* [Introduction: Business Problem](#introduction)\n",
    "* [Data Collection](#data)\n",
    "* [Methodology](#methodology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Business Problem  <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem statement for this project will be:  \n",
    "> **_\"What types of restaurants are available in New York, USA and Toronto, Canada?\"_**\n",
    "\n",
    "No matter where in the world you travel, food is the most talked about topic. In this project, I would like to focus on whether there is a variety of restaurants available for all travellers in the 2 big cities: New York, USA and Toronto, Canada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection  <a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will be using different sources to extract data.  \n",
    "For the New York, USA the data provided on **NYU Spatial Data Repository** website will be used. It contains the Boroughs, Neighborhoods and their Latitude and Longitude details. The dataframe contains 5 boroughs and 306 neighborhoods.\n",
    "\n",
    "For Toronto, Canada the data for Neighborhoods is scraped from **Wikipedia** and their geographical coordinates were provided from a previous module in the **IBM Coursera Data Science** course. The data consists of the postcodes, boroughs, neighborhoods and their latitude and longitude. The dataframe contains 11 Boroughs and 103 Neighborhoods.\n",
    "\n",
    "The process of web scraping is made simpler with the use of 2 libraries: **Requests** and **Beautiful Soup**. The Requests library allows you to make use of HTTP within your Python programs in a human readable way, and the Beautiful Soup module is designed to get web scraping of HTML and XML pages done quickly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology  <a name=\"methodology\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected for the 2 big cities contains the locations and their geographic coordinates. \n",
    "\n",
    "Based on the open data available on the web, I will focus on the most populated Boroughs in New York and Toronto. Data from **data.gov** website for New York and data from the **National Statistics Office** website for Toronto.\n",
    "\n",
    "Once I have the location details, I still require data for restaurants. In order to retrieve this information, I am going to use **Foursquare API** to retrieve location based restaurants in the 2 big cities. By using the **Folium map** library in Python, I will be able to visually display the locations.  \n",
    "\n",
    "And finally, by using **K-Means clustering** algotritm, I will be grouping the data into 5 clusters and analyze where the majority of these restaurants are located."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
